{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWKmoC9KFsLy0XrhtkUmsz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"qzWGSs0Ch1h1","executionInfo":{"status":"ok","timestamp":1610843424917,"user_tz":480,"elapsed":355,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"3f97e598-b0e3-4781-e9e9-8ac17e0da587"},"source":["\"\"\" \n","this is a pytorch implementation of alexnet, trained and validated on \n","CIFAR-10.\n","\n","first time implementing a deep learning paper. \n","\n","using CIFAR-10 because ImageNet is too big to do locally\n","\n","\"\"\"\n","\n","### TODO ### \n","# - import dependencies \n","# - load the data\n","# - set up model architecture\n","# - define the forward pass \n","# - write a training loop\n","# - train and validate model\n","# - final accuracy on test data\n","\n","### add later ###\n","# - visualize loss \n","# - visualize data\n","# - figure out how to get ImageNet"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' \\nthis is a pytorch implementation of alexnet, trained and validated on \\nCIFAR-10.\\n\\nfirst time implementing a deep learning paper. \\n\\nusing CIFAR-10 because ImageNet is too big to do locally\\n\\n'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kqGtdW5XjwQ4","executionInfo":{"status":"ok","timestamp":1610843427626,"user_tz":480,"elapsed":1620,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"daa501c6-6b23-440d-dfc8-6f11022852bf"},"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n","FOLDERNAME = 'cs231n'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# this downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","%cd drive/My\\ Drive/$FOLDERNAME/paper\\ implementations/datasets\n","!bash get_datasets.sh\n","%cd /content"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive/cs231n/paper implementations/datasets\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"90iHePg-iC7m","executionInfo":{"status":"ok","timestamp":1610843429238,"user_tz":480,"elapsed":324,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["import torch\n","import torch.nn as nn\n","\n","# to load the data\n","from torch.utils.data import DataLoader\n","\n","# optimizer \n","import torch.optim as optim\n","\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T \n","\n","import torch.nn.functional as F  # useful stateless functions\n","\n","import numpy as np"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnpp9AJiiDKS","executionInfo":{"status":"ok","timestamp":1610843430531,"user_tz":480,"elapsed":315,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"d2ee643b-8e13-45ec-fed7-a64cda8beec1"},"source":["USE_GPU = True\n","\n","dtype = torch.float32 # we will be using float throughout this tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","print('using device:', device)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["using device: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s-SD5nVRiDV1","executionInfo":{"status":"ok","timestamp":1610843431946,"user_tz":480,"elapsed":312,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["# set up preprocessing transformations: \n","# - resize to 256x256\n","# - take center crops 224x224\n","# - center with mean\n","\n","# original paper resized image to 224x224, skip that becuase CIFAR-10\n","# has tiny images \n","\n","\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n","            ])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLkMReNDiDqZ","executionInfo":{"status":"ok","timestamp":1610843436290,"user_tz":480,"elapsed":3088,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"e73eca4e-336c-40d4-9b92-cd261359ae38"},"source":["# load the data using a Dataset object and DataLoader wrapper\n","NUM_TRAIN = 49000\n","\n","cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=64, \n","                         sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./datasets', train=True, download=True, \n","                          transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=64, \n","                       sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./datasets', train=False, download=True, \n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mQzZq_3TiEEU","executionInfo":{"status":"ok","timestamp":1610843611489,"user_tz":480,"elapsed":592,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["# set up model architecture\n","\n","\"\"\"\n","model details: \n","- 5 conv layers\n","- 3 FC layers\n","- relu nonlinearities\n","- local response normalization\n","- dropout\n","- momentum\n","- flatten between conv and fc layers\n","\"\"\"\n","\n","class AlexNet(nn.Module): \n","  def __init__(self, num_classes=10):\n","    super().__init__()\n","\n","    # conv layers \n","    self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=2)\n","    self.conv2 = nn.Conv2d(96, 256, kernel_size=3, stride=1, padding=2)\n","    self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=2)\n","    self.conv4 = nn.Conv2d(384, 192, kernel_size=3, stride=1, padding=2)\n","    self.conv5 = nn.Conv2d(192, 2, kernel_size=3, stride=1, padding=2)\n","\n","    # fully connected layers \n","    self.fc1 = nn.Linear(392, 4096)\n","    self.fc2 = nn.Linear(4096, 4096)\n","    self.fc3 = nn.Linear(4096, num_classes)\n","\n","    # overlapping pool where s < z \n","    self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n","\n","    # use F.relu for relu\n","\n","    # local response norm\n","    # TODO: calc dims\n","    self.localresponsenorm = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0)\n","\n","    # dropout regularization\n","    self.dropout = nn.Dropout()\n","\n","    \n","  def forward(self, x): \n","    # define connectivity\n","    x = self.conv1(x)\n","    x = self.localresponsenorm(x)\n","    x = F.relu(x)\n","    x = self.pool(x)\n","\n","    x = self.conv2(x)\n","    x = self.localresponsenorm(x)\n","    x = F.relu(x)\n","    x = self.pool(x)\n","\n","    x = self.conv3(x)\n","    x = F.relu(x)\n","    x = self.conv4(x)\n","    x = F.relu(x)\n","    x = self.conv5(x)\n","    x = F.relu(x)\n","\n","    x = torch.flatten(x, 1)\n","    x = self.dropout(x)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","\n","    x = self.dropout(x)\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","\n","    x = self.dropout(x)\n","    scores = self.fc3(x)\n","\n","    return scores"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvLjdCifiLFX","executionInfo":{"status":"ok","timestamp":1610843616647,"user_tz":480,"elapsed":371,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["def check_accuracy(loader, model): \n","    if loader.dataset.train: \n","        print('checking validation set')\n","    else: \n","        print('checking test set')\n","    num_correct, num_samples = 0, 0\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in loader: \n","            # put onto device (here using cpu)\n","            x = x.to(device=device, dtype=dtype)\n","            y = y.to(device=device, dtype=torch.long)\n","            \n","            # scores of val/test set\n","            scores = model(x)\n","            \n","            # preds are argmaxes of scores\n","            # torch.max returns tuple (values, indices)\n","            _, preds = scores.max(1)\n","            \n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('%d / %d correct (%.2f)' % (num_correct, num_samples, 100*acc))\n","            "],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQ7adwrjiLcY","executionInfo":{"status":"ok","timestamp":1610843618092,"user_tz":480,"elapsed":336,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["def train(model, optimizer, epochs=1):\n","    model = model.to(device=device)\n","    for e in range(epochs): \n","        for t, (x, y) in enumerate(loader_train): \n","\n","            # puts model in train mode. call model.eval() for testing\n","            model.train() \n","\n","            # put onto device (here using cpu)\n","            x = x.to(device=device, dtype=dtype)\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            # forward pass \n","            scores = model(x)\n","\n","            # loss\n","            loss =  F.cross_entropy(scores, y)\n","\n","            # zero the gradients\n","            optimizer.zero_grad()\n","            \n","            # backward pass\n","            loss.backward()\n","\n","            # update parameters\n","            optimizer.step()\n","\n","            # print progress \n","            if t % 100 == 0: \n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy(loader_val, model)\n","                print()\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OdcNzoxme7B","executionInfo":{"status":"ok","timestamp":1610843657710,"user_tz":480,"elapsed":482,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":["model = AlexNet()\n","optimizer = optim.Adam(model.parameters())"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjLo_RqyiLxh","executionInfo":{"status":"ok","timestamp":1610844059942,"user_tz":480,"elapsed":359529,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"a4ef370f-4963-416d-9375-99ca1439ec06"},"source":["# train the net\n","train(model, optimizer, epochs=10)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Iteration 0, loss = 1.5501\n","checking validation set\n","473 / 1000 correct (47.30)\n","\n","Iteration 100, loss = 1.3336\n","checking validation set\n","486 / 1000 correct (48.60)\n","\n","Iteration 200, loss = 1.5889\n","checking validation set\n","509 / 1000 correct (50.90)\n","\n","Iteration 300, loss = 1.4998\n","checking validation set\n","548 / 1000 correct (54.80)\n","\n","Iteration 400, loss = 1.3597\n","checking validation set\n","519 / 1000 correct (51.90)\n","\n","Iteration 500, loss = 1.4498\n","checking validation set\n","549 / 1000 correct (54.90)\n","\n","Iteration 600, loss = 1.2282\n","checking validation set\n","561 / 1000 correct (56.10)\n","\n","Iteration 700, loss = 1.2364\n","checking validation set\n","530 / 1000 correct (53.00)\n","\n","Iteration 0, loss = 1.2254\n","checking validation set\n","549 / 1000 correct (54.90)\n","\n","Iteration 100, loss = 1.1313\n","checking validation set\n","544 / 1000 correct (54.40)\n","\n","Iteration 200, loss = 1.3164\n","checking validation set\n","597 / 1000 correct (59.70)\n","\n","Iteration 300, loss = 1.4482\n","checking validation set\n","591 / 1000 correct (59.10)\n","\n","Iteration 400, loss = 1.0663\n","checking validation set\n","609 / 1000 correct (60.90)\n","\n","Iteration 500, loss = 0.9925\n","checking validation set\n","613 / 1000 correct (61.30)\n","\n","Iteration 600, loss = 1.0012\n","checking validation set\n","627 / 1000 correct (62.70)\n","\n","Iteration 700, loss = 1.4352\n","checking validation set\n","620 / 1000 correct (62.00)\n","\n","Iteration 0, loss = 1.3281\n","checking validation set\n","641 / 1000 correct (64.10)\n","\n","Iteration 100, loss = 1.1258\n","checking validation set\n","646 / 1000 correct (64.60)\n","\n","Iteration 200, loss = 1.1172\n","checking validation set\n","634 / 1000 correct (63.40)\n","\n","Iteration 300, loss = 1.0961\n","checking validation set\n","628 / 1000 correct (62.80)\n","\n","Iteration 400, loss = 1.1606\n","checking validation set\n","663 / 1000 correct (66.30)\n","\n","Iteration 500, loss = 1.0861\n","checking validation set\n","635 / 1000 correct (63.50)\n","\n","Iteration 600, loss = 0.8308\n","checking validation set\n","643 / 1000 correct (64.30)\n","\n","Iteration 700, loss = 1.1179\n","checking validation set\n","659 / 1000 correct (65.90)\n","\n","Iteration 0, loss = 0.8434\n","checking validation set\n","629 / 1000 correct (62.90)\n","\n","Iteration 100, loss = 0.9635\n","checking validation set\n","648 / 1000 correct (64.80)\n","\n","Iteration 200, loss = 0.9956\n","checking validation set\n","660 / 1000 correct (66.00)\n","\n","Iteration 300, loss = 1.1350\n","checking validation set\n","634 / 1000 correct (63.40)\n","\n","Iteration 400, loss = 1.1095\n","checking validation set\n","648 / 1000 correct (64.80)\n","\n","Iteration 500, loss = 0.8745\n","checking validation set\n","671 / 1000 correct (67.10)\n","\n","Iteration 600, loss = 1.2669\n","checking validation set\n","652 / 1000 correct (65.20)\n","\n","Iteration 700, loss = 1.0463\n","checking validation set\n","652 / 1000 correct (65.20)\n","\n","Iteration 0, loss = 0.9257\n","checking validation set\n","661 / 1000 correct (66.10)\n","\n","Iteration 100, loss = 0.9704\n","checking validation set\n","661 / 1000 correct (66.10)\n","\n","Iteration 200, loss = 1.2798\n","checking validation set\n","681 / 1000 correct (68.10)\n","\n","Iteration 300, loss = 1.0075\n","checking validation set\n","665 / 1000 correct (66.50)\n","\n","Iteration 400, loss = 0.9806\n","checking validation set\n","702 / 1000 correct (70.20)\n","\n","Iteration 500, loss = 0.9692\n","checking validation set\n","695 / 1000 correct (69.50)\n","\n","Iteration 600, loss = 1.1486\n","checking validation set\n","677 / 1000 correct (67.70)\n","\n","Iteration 700, loss = 1.1647\n","checking validation set\n","669 / 1000 correct (66.90)\n","\n","Iteration 0, loss = 0.8804\n","checking validation set\n","687 / 1000 correct (68.70)\n","\n","Iteration 100, loss = 1.1591\n","checking validation set\n","706 / 1000 correct (70.60)\n","\n","Iteration 200, loss = 1.0241\n","checking validation set\n","697 / 1000 correct (69.70)\n","\n","Iteration 300, loss = 1.0825\n","checking validation set\n","681 / 1000 correct (68.10)\n","\n","Iteration 400, loss = 1.0492\n","checking validation set\n","692 / 1000 correct (69.20)\n","\n","Iteration 500, loss = 0.9026\n","checking validation set\n","703 / 1000 correct (70.30)\n","\n","Iteration 600, loss = 0.9579\n","checking validation set\n","694 / 1000 correct (69.40)\n","\n","Iteration 700, loss = 0.9209\n","checking validation set\n","708 / 1000 correct (70.80)\n","\n","Iteration 0, loss = 0.7911\n","checking validation set\n","705 / 1000 correct (70.50)\n","\n","Iteration 100, loss = 0.8972\n","checking validation set\n","686 / 1000 correct (68.60)\n","\n","Iteration 200, loss = 0.5832\n","checking validation set\n","682 / 1000 correct (68.20)\n","\n","Iteration 300, loss = 1.0103\n","checking validation set\n","704 / 1000 correct (70.40)\n","\n","Iteration 400, loss = 1.0812\n","checking validation set\n","683 / 1000 correct (68.30)\n","\n","Iteration 500, loss = 0.8786\n","checking validation set\n","696 / 1000 correct (69.60)\n","\n","Iteration 600, loss = 1.2374\n","checking validation set\n","693 / 1000 correct (69.30)\n","\n","Iteration 700, loss = 0.8124\n","checking validation set\n","703 / 1000 correct (70.30)\n","\n","Iteration 0, loss = 0.6638\n","checking validation set\n","722 / 1000 correct (72.20)\n","\n","Iteration 100, loss = 0.7739\n","checking validation set\n","708 / 1000 correct (70.80)\n","\n","Iteration 200, loss = 0.8786\n","checking validation set\n","732 / 1000 correct (73.20)\n","\n","Iteration 300, loss = 0.8971\n","checking validation set\n","696 / 1000 correct (69.60)\n","\n","Iteration 400, loss = 0.9442\n","checking validation set\n","712 / 1000 correct (71.20)\n","\n","Iteration 500, loss = 0.7068\n","checking validation set\n","704 / 1000 correct (70.40)\n","\n","Iteration 600, loss = 0.8835\n","checking validation set\n","711 / 1000 correct (71.10)\n","\n","Iteration 700, loss = 0.8240\n","checking validation set\n","723 / 1000 correct (72.30)\n","\n","Iteration 0, loss = 0.8658\n","checking validation set\n","714 / 1000 correct (71.40)\n","\n","Iteration 100, loss = 0.6641\n","checking validation set\n","723 / 1000 correct (72.30)\n","\n","Iteration 200, loss = 0.9299\n","checking validation set\n","722 / 1000 correct (72.20)\n","\n","Iteration 300, loss = 0.7607\n","checking validation set\n","722 / 1000 correct (72.20)\n","\n","Iteration 400, loss = 0.7347\n","checking validation set\n","727 / 1000 correct (72.70)\n","\n","Iteration 500, loss = 0.7334\n","checking validation set\n","705 / 1000 correct (70.50)\n","\n","Iteration 600, loss = 0.7557\n","checking validation set\n","734 / 1000 correct (73.40)\n","\n","Iteration 700, loss = 1.0943\n","checking validation set\n","714 / 1000 correct (71.40)\n","\n","Iteration 0, loss = 0.8561\n","checking validation set\n","710 / 1000 correct (71.00)\n","\n","Iteration 100, loss = 0.5863\n","checking validation set\n","724 / 1000 correct (72.40)\n","\n","Iteration 200, loss = 0.6664\n","checking validation set\n","722 / 1000 correct (72.20)\n","\n","Iteration 300, loss = 0.7971\n","checking validation set\n","727 / 1000 correct (72.70)\n","\n","Iteration 400, loss = 0.7362\n","checking validation set\n","734 / 1000 correct (73.40)\n","\n","Iteration 500, loss = 0.7385\n","checking validation set\n","739 / 1000 correct (73.90)\n","\n","Iteration 600, loss = 0.9417\n","checking validation set\n","708 / 1000 correct (70.80)\n","\n","Iteration 700, loss = 0.6978\n","checking validation set\n","717 / 1000 correct (71.70)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZlN6gUCiL_X","executionInfo":{"status":"ok","timestamp":1610844087244,"user_tz":480,"elapsed":2920,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}},"outputId":"b9550c98-b5cd-44e4-bbdb-7606ec9e2845"},"source":["# for test set evaluation\n","best_model = model\n","check_accuracy(loader_test, best_model)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["checking test set\n","7074 / 10000 correct (70.74)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u50ANQRWiMOm","executionInfo":{"status":"aborted","timestamp":1610842241520,"user_tz":480,"elapsed":15764,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaTCj1A1iMiR","executionInfo":{"status":"aborted","timestamp":1610842241521,"user_tz":480,"elapsed":15763,"user":{"displayName":"Neeraj Arunkumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVNko1QtBZK7-53rBPMMD6FmM_NlTvDrk2pb_f6Yc=s64","userId":"14879940715102477088"}}},"source":[""],"execution_count":null,"outputs":[]}]}